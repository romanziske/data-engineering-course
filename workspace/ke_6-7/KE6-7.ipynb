{
 "cells": [
  {
   "cell_type": "raw",
   "id": "15b94051",
   "metadata": {},
   "source": [
    "Name:\n",
    "Matrikelnummer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4b8e40",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb480d",
   "metadata": {},
   "source": [
    "# (I can't get no) satisfaction\n",
    "\n",
    "Ziel dieser Kurseinheit ist es, Erfahrung mit der Datenmodellierung für dokument-orientierte und spalten-orientierte Datenbanksysteme (im Vergleich zu relationalen Systemen) zu sammeln."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4da72b",
   "metadata": {},
   "source": [
    "##  Datenmodellierung (konzeptionell)\n",
    "\n",
    "Wir beginnen mit einer Analyse der zur Verfügung stehenden Dateien bzw. Daten, die in die verschiedenen Datenbanksysteme importiert werden sollen.\n",
    "\n",
    "Neben der bereits verwendeten Datei:\n",
    "\n",
    "- *employees_satisfaction_transformed.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24233efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Show the headline from file \"employees_satisfaction_transformed.csv\"\n",
    "printf \"\\n## Employee columns\\n\"\n",
    "head -1 ~/path/to/employees_satisfaction_transformed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a01479",
   "metadata": {},
   "source": [
    "werden zwei weitere Dateien bereitgestellt:\n",
    "\n",
    "- *departments.csv*\n",
    "\n",
    "- *projects.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5daf7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Show the headline from file \"departments.csv\"\n",
    "printf \"\\n## Department columns:\\n\"\n",
    "head -1 ~/path/to/departments.csv\n",
    "\n",
    "# Show the headline from file \"projects.csv\"\n",
    "printf \"\\n## Project columns\\n\"\n",
    "head -1 ~/path/to/projects.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c6b43",
   "metadata": {},
   "source": [
    "> *HINWEIS:* Die Binärdaten der Bilddateien (*Projects.proj_image*) sind base64 encodiert!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121aa86",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 1**    \n",
    "    \n",
    "Erstellen Sie ein konzeptionelles Klassen-Diagramm, das sich implizit aus den vorhandenen Daten ergibt. Markieren Sie farblich im Diagramm die in den vorliegenden Daten fehlenden Schlüsselattribute.\n",
    "</div>\n",
    "\n",
    "\n",
    "Folgende Beziehungen sollen modelliert werden:\n",
    "\n",
    "- Ein Department hat mehrere Projekte, aber ein Projekt ist immer genau einem Department zugeordnet\n",
    "- Ein Department hat viele Mitarbeiter, aber ein Mitarbeiter ist wieder nur einem Department zugeordnet\n",
    "\n",
    "\n",
    "\n",
    "> *HINWEIS:* Für die Modellierung verwenden wir PlantUML innerhalb der Jupyter-Notebook-Zellen. Eine Dokumentation zu PlantUML ist unter folgender URL zu finden: [https://plantuml.com/class-diagram](https://plantuml.com/class-diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e74725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import iplantuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a4500",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%plantuml --jar\n",
    "\n",
    "@startuml\n",
    "\n",
    "hide circle\n",
    "hide members\n",
    "show fields\n",
    "\n",
    "class \"A\" as a {\n",
    "    * <color:Tomato>**id <<PK>>**</color>\n",
    "}\n",
    "\n",
    "class \"B\" as b {\n",
    "}\n",
    "\n",
    "a \"1\" -- \"0..*\" b : c >\n",
    "\n",
    "@enduml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2926ccc8",
   "metadata": {},
   "source": [
    "## PostgreSQL    \n",
    "\n",
    "Im Folgenden sollen die vorhandenen Daten zunächst in ein relationales Datenbanksystem - in diesem Fall PostgreSQL - importiert werden.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 2**    \n",
    "    \n",
    "Bilden Sie das in Aufgabe 1 entwickelte konzeptionelle Modell jetzt geeignet auf das relationale Datenmodell ab (inklusive Datentypen). Markieren Sie ebenfalls wieder farblich für die Modellierung notwendige Attribute, die in den vorhandenen Daten fehlen. Kennzeichnen Sie ebenfalls Attribute die Sie entfernen. \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe68f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%plantuml --jar\n",
    "\n",
    "@startuml\n",
    "\n",
    "   \n",
    "@enduml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab5c7fe",
   "metadata": {},
   "source": [
    "### Data Preparation   \n",
    "\n",
    "$$ \\\\ $$\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Aufgabe 3**\n",
    "    \n",
    "Nehmen Sie an dieser Stelle für den Import möglicherweise notwendige Änderungen an den Daten vor. Es steht Ihnen frei dies mithilfe von Bash-Tools, Python-Skripten oder sonstigen Werkzeugen umzusetzen. \n",
    "\n",
    "Beschreiben Sie außerdem nachvollziehbar - mit Kommentaren im Code oder Markdown-Zellen - welche Änderungen Sie vornehmen und wieso Sie diese vornehmen.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a2e26",
   "metadata": {},
   "source": [
    "Ihre Lösung ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dd1c7a",
   "metadata": {},
   "source": [
    "### Datenimport     \n",
    "\n",
    "\n",
    "Starten Sie jetzt einen Docker-Container mit einer PostgreSQL-Datenbank, innerhalb des Docker-Netzwerks, in dem sich alle weiteren hier verwendeten Container befinden.\n",
    "\n",
    "> *HINWEIS:* Denken Sie bezüglich der zu importierenden Dateien daran den vollständigen Pfad des Volumes anzugeben (`-v /PATH/ON/HOST:/PATH/INSIDE/CONTAINER`), das im Datenbank-Container verfügbar sein soll. Also das Verzeichnis, das die zu importierenden CSV-Dateien enthält. Hier muss der absolute Pfad des entsprechenden Verzeichnisses auf ihrem Rechner (Host) angegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe234fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo docker run -d --rm \\\n",
    "--name dbis-postgres-db-1 \\\n",
    "--hostname dbis-postgres-db-1 \\\n",
    "-v \"/CHANGE/ME!!!:/mnt/workspace:ro\" \\\n",
    "-e POSTGRES_PASSWORD=root \\\n",
    "-p 127.0.0.1:5432:5432 \\\n",
    "--network dbis-hadoop-cluster-network \\\n",
    "postgres:14.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea80bf65",
   "metadata": {},
   "source": [
    "Vergewissern Sie sich, dass der Container läuft:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44414ac0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo docker ps --filter \"name=dbis-postgres-db-1\" --format \"table {{.Names}}\\t{{.Status}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce252c6d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 4**    \n",
    "    \n",
    "Schreiben Sie ein SQL-Skript, das die notwendigen Schema-Strukturen anlegt, die CSV-Dateien einliest und entsprechend dem in Aufgabe 2 entworfenem Modell \"Umstrukturierungen\" vornimmt. Vervollständigen Sie hierzu das nachfolgende SQL-Skript.\n",
    "\n",
    "Sie können natürlich auch abweichend alternative Methoden bzw. Tools verwenden. Der Python-Treiber für PostgreSQL ([psycopg](https://www.psycopg.org/psycopg3/docs/)) ist bereits installiert.\n",
    "</div>\n",
    "\n",
    "\n",
    "> *HINWEIS:* Der Import der Daten kann mehrere Minuten in Anspruch nehmen! Bezüglich der benötigten SQL-Aufrufe kann die Online-Dokumentation von PostgreSQL hilfreich sein (beispielsweise hinsichtlich des *COPY-FROM*-Befehls: [https://www.postgresql.org/docs/14/sql-copy.html](https://www.postgresql.org/docs/14/sql-copy.html)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f0f28e",
   "metadata": {},
   "source": [
    "Codeauschnitt für die Verwendung des Python-Treibers (Verbindungsaufbau mit einer PostgreSQL-Datenbank mithilfe des *pscopg*-Python-Modules):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "\n",
    "postgres_conn = psycopg.connect(\"host='dbis-postgres-db-1' dbname='satisfaction' user='postgres' password='root'\")\n",
    "postgres_cursor = postgres_conn.cursor()\n",
    "\n",
    "# ...\n",
    "\n",
    "postgres_cursor.close()\n",
    "postgres_conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16267980",
   "metadata": {},
   "source": [
    "Vorgegebener \"Rahmen\" des SQL-Skripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97edf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat <<\"EOF\" | sudo docker exec -i dbis-postgres-db-1 psql -U postgres\n",
    "\n",
    "DROP DATABASE IF EXISTS satisfaction;\n",
    "CREATE DATABASE satisfaction;\n",
    "\\c satisfaction;\n",
    "\n",
    "\n",
    "CREATE TABLE ... (\n",
    "\n",
    "...\n",
    "\n",
    ");\n",
    "\n",
    "COPY ...\n",
    "FROM '/path/to/file.csv'\n",
    "CSV DELIMITER ',';\n",
    "\n",
    "...\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9933fcb6",
   "metadata": {},
   "source": [
    "### Datenbankabfragen    \n",
    "\n",
    "$$ \\\\ $$\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 5**    \n",
    "    \n",
    "Schreiben Sie nun für nachfolgende Abfragen SQL-Statements und führen diese aus. Sie können entweder das vorgegebene SQL-Skript oder den Python-Treiber verwenden. Zu jeder Abfrage werden außerdem die Attribute angegeben, die jeweils ausgegeben werden sollen.\n",
    "</div>\n",
    "\n",
    "- **Q1. Anzahl Projekte pro Department**\n",
    "    - Auszugebende Attribute: *Department.id, Department.name, Department.city, Department.zip_code, count_projects*\n",
    "    - Erwartetes Ergebnis:\n",
    "\n",
    "\n",
    " id  |    name    |      city      | zip_code | count_projects \n",
    "-----|------------|----------------|----------|----------------\n",
    " 101 | HR         | Frankfurt a.M. |    60306 |             85\n",
    " 103 | Purchasing | München        |    80331 |            102\n",
    " 104 | Sales      | Hamburg        |    21140 |             59\n",
    " 105 | Technology | Berlin         |    10115 |            406\n",
    " 102 | Marketing  | Berlin         |    10115 |            348\n",
    "  \n",
    "\n",
    "- **Q2. Durchschnittliche Dauer aller Projekte**\n",
    "    - Auszugebende Attribute: *avg_project_duration_days*\n",
    "    - Erwartetes Ergebnis:\n",
    "    \n",
    "|  avg_proj_duration_days |\n",
    "|-------------------------|\n",
    "|   932.6690000000000000  |\n",
    "  \n",
    "- **Q3. Durchschnittliche Projektdauer pro Department**\n",
    "    - Auszugebende Attribute: *Department.id, Department.name, Department.city, Department.zip_code, avg_project_duration_days*\n",
    "    - Erwartetes Ergebnis:   \n",
    "  \n",
    "\n",
    " id  |    name    |      city      | zip_code | avg_proj_duration_days \n",
    "-----|------------|----------------|----------|------------------------\n",
    " 101 | HR         | Frankfurt a.M. |    60306 |   992.2000000000000000\n",
    " 103 | Purchasing | München        |    80331 |   993.4509803921568627\n",
    " 104 | Sales      | Hamburg        |    21140 |   856.1864406779661017\n",
    " 105 | Technology | Berlin         |    10115 |   946.0270935960591133\n",
    " 102 | Marketing  | Berlin         |    10115 |   897.6954022988505747\n",
    " \n",
    "\n",
    "- **Q4. Durchschnittliche Saturation pro Department**\n",
    "    - Auszugebende Attribute: *Department.id, Department.name, Department.city, Department.zip_code, avg_satisfied*\n",
    "    - Erwartetes Ergebnis:   \n",
    "\n",
    "\n",
    " id  |    name    |      city      | zip_code |     avg_satisfied      \n",
    "-----|------------|----------------|----------|------------------------\n",
    " 101 | HR         | Frankfurt a.M. |    60306 | 0.68867924528301886792\n",
    " 103 | Purchasing | München        |    80331 | 0.70175438596491228070\n",
    " 104 | Sales      | Hamburg        |    21140 | 0.80459770114942528736\n",
    " 105 | Technology | Berlin         |    10115 | 0.74489795918367346939\n",
    " 102 | Marketing  | Berlin         |    10115 | 0.64516129032258064516\n",
    "    \n",
    "\n",
    "- **Q5. Durchschnittliche Projektdauer des \"Technology\" Departments**\n",
    "    - Auszugebende Attribute: *Department.name, Department.city, Department.zip_code, avg_proj_duration_days*\n",
    "    - Erwartetes Ergebnis:\n",
    "\n",
    "\n",
    " id  |    name    |  city  | zip_code | avg_proj_duration_days \n",
    "-----|------------|--------|----------|------------------------\n",
    " 105 | Technology | Berlin |    10115 |   946.0270935960591133    \n",
    "\n",
    "\n",
    "- **Q6. Satisfaction des \"Technology\" Departments**\n",
    "    - Auszugebende Attribute: *Department.name, Department.city, Department.zip_code, avg_satisfied*\n",
    "    - Erwartetes Ergebnis:\n",
    "\n",
    "\n",
    " id  |    name    |  city  | zip_code |     avg_satisfied      \n",
    "-----|------------|--------|----------|------------------------\n",
    " 105 | Technology | Berlin |    10115 | 0.74489795918367346939\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a3df0a",
   "metadata": {},
   "source": [
    "Vorgegebener \"Rahmen\" des SQL-Skripts für die Abfragen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ca74f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<\"EOF\" | sudo docker exec -i dbis-postgres-db-1 psql -U postgres -d satisfaction\n",
    "\n",
    "\\qecho ******** Q1 ********\n",
    "SELECT ... FROM ...\n",
    "\n",
    "\n",
    "\\qecho ******** Q2 ********\n",
    "SELECT ... FROM ...\n",
    "\n",
    "...\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03415b8e",
   "metadata": {},
   "source": [
    "Abschließend kann der Datenbank-Container folgendermaßen wieder gestoppt werden (zu beachten gilt, dass aufgrund des `--rm` Flags der Container nach dem Stoppen automatisch gelöscht wird): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d91dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# stop the postgresql docker container\n",
    "if [ -z $(sudo docker ps --filter \"name=dbis-postgres-db-1\" -q) ]; then\n",
    "    printf \"\\nthe container does not exist\\n\";\n",
    "else \n",
    "    printf \"\\nstopping the container ...\\n\";\n",
    "    sudo docker stop dbis-postgres-db-1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03717155",
   "metadata": {},
   "source": [
    "## MongoDB    \n",
    "\n",
    "Nachdem die zur Verfügung stehenden Daten in ein relationales Datenbanksystem importiert wurden, beschäftigen wir uns im Folgenden mit der Modellierung und Import bezüglich des dokument-orientierten Datenbanksystems MongoDB.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 6**    \n",
    "    \n",
    "Bilden Sie das konzeptionelle Modell (Aufgabe 1) jetzt geeignet auf das Modell von MongoDB ab (inklusive Datentypen). Optimieren bzw. gestalten Sie das Modell so, dass für die geplanten Abfragen keine Joins benötigt werden ([*\\$lookup*](https://www.mongodb.com/docs/manual/reference/operator/aggregation/lookup/))! Begründen Sie ihre Entscheidungen bezüglich des Schema-Designs, wo dieses vom konzeptionellen Modell abweichen.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a9390",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%plantuml --jar\n",
    "\n",
    "@startuml\n",
    "\n",
    "   \n",
    "@enduml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b178052",
   "metadata": {},
   "source": [
    "### Datenimport    \n",
    "\n",
    "Starten Sie jetzt eine MongoDB Datenbank innerhalb des Docker-Netzwerks in dem sich alle weiteren hier verwendeten Container befinden.\n",
    "\n",
    "> *HINWEIS:* Denken Sie bezüglich der zu importierenden Dateien wieder daran den vollständigen Pfad des Volumes anzugeben (`-v /PATH/ON/HOST:/PATH/INSIDE/CONTAINER`), das im Datenbank-Container verfügbar sein soll. Also das Verzeichnis, das die zu importierenden CSV-Dateien enthält. Hier muss der absolute Pfad des entsprechenden Verzeichnisses auf ihrem Rechner (Host) angegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04160b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo docker run -d --rm \\\n",
    "--name dbis-mongo-db-1 \\\n",
    "--hostname dbis-mongo-db-1 \\\n",
    "-v \"/CHANGE/ME!!!:/mnt/workspace:ro\" \\\n",
    "-e BROWSERSLIST_IGNORE_OLD_DATA=1 \\\n",
    "--network dbis-hadoop-cluster-network \\\n",
    "-p 127.0.0.1:27017:27017 \\\n",
    "mongo:5.0.5-focal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a24c5",
   "metadata": {},
   "source": [
    "Vergewissern Sie sich wieder, dass der Container läuft:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c9ce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo docker ps --filter \"name=dbis-mongo-db-1\" --format \"table {{.Names}}\\t{{.Status}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d343c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 7**    \n",
    "    \n",
    "Importieren Sie die Daten nach MongoDB (schauen Sie sich diesbezüglich die Dokumentation zu [mongoimport](https://www.mongodb.com/docs/database-tools/mongoimport/) an). Achten Sie insbesondere auf die entsprechenden Datentypen.\n",
    "    \n",
    "Nehmen Sie außerdem bezüglich dem in Aufgabe 6 erstellten Modell notwendige \"Umstrukturierungen\" der Daten vor. Hierbei sind unterschiedliche Vorgehensweisen denkbar. Es können Beispielsweise die Daten zunächst so wie sie vorliegen in MongoDB importiert und anschließend durch entsprechende Aufrufe (*\\$lookup*, *\\$addFields*, *\\$merge*, ...) umstrukturiert werden. Die Daten können natürlich auch vorher - beispielsweise mit Python - in die benötigte Struktur überführt und anschließend importiert werden.\n",
    "\n",
    "Abweichend zu *mongoimport* kann hier auch der [*pymongo*](https://pymongo.readthedocs.io/en/stable/) Python-Treiber verwendet werden. Dieser ist ebenfalls bereits installiert.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239651f6",
   "metadata": {},
   "source": [
    "Codeauschnitt für die Verwendung des Python-Treibers (Verbindungsaufbau mit einer Mongo-Datenbank mithilfe des *pymongo*-Python-Modules):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a45f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "\n",
    "mongo_client = MongoClient('mongodb://dbis-mongo-db-1:27017/')\n",
    "mongo_db = mongo_client['satisfaction']\n",
    "\n",
    "pipeline = [\n",
    "    # Mongo-pipeline\n",
    "]\n",
    "    \n",
    "result = mongo_db['Project'].aggregate(pipeline)\n",
    "pprint(list(q1_result)\n",
    "       \n",
    "mongo_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03380f4",
   "metadata": {},
   "source": [
    "Vorgegebener \"Rahmen\" für die Verwendung von *mongoimport*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12bbe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## import a CSV-file with mongoimport\n",
    "sudo docker exec -i dbis-mongo-db-1 mongoimport \\\n",
    "--drop \\\n",
    "--db=satisfaction \\\n",
    "--file=/path/to/file.csv \\\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e42f52",
   "metadata": {},
   "source": [
    "### Datenbankabfragen    \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 8**    \n",
    "    \n",
    "Führen Sie nun wieder die vorgegeben Abfragen aus (siehe Aufgabe 5). Nochmals der Hinweis, dass keine Joins (*\\$lookup*) verwendet werden sollen. Außerdem sollten *\\$unwind*-Operationen möglichst vermieden werden.\n",
    "\n",
    "Alternativ zu dem vorgegebenen Rahmen (Verwendung der Mongo-Shell) können Sie ebenfalls den *pymongo* Python-Treiber verwenden.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812791ad",
   "metadata": {},
   "source": [
    "*Q1*. Anzahl Projekte pro Department "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57dcd7d",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Unter dem \"Show Solution\"-Button finden Sie als Einstiegshilfe einen Lösungsvorschlag zu Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c173d9",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Mögliche Lösung zu Q1:\n",
    "```js\n",
    "db.Project.aggregate([   \n",
    "        {\n",
    "            $group: {\n",
    "                _id: \"$department_name\",\n",
    "                count_projects: {\n",
    "                    $count: { }\n",
    "                },\n",
    "                city: { $first: \"$department_city\" },\n",
    "                zip_code: { $first: \"$department_zip_code\" }\n",
    "            }\n",
    "        }\n",
    "]);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898830b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo docker exec -i dbis-mongo-db-1 mongosh satisfaction --quiet --eval \\\n",
    "'print(\"******** Q1 ******** \");\n",
    "db.X.aggregate([  \n",
    "\n",
    "        ...\n",
    "        \n",
    "]);'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54113787",
   "metadata": {},
   "source": [
    "*Q2*. Durchschnittliche Projektdauer aller Projekte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cf7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo docker exec -i dbis-mongo-db-1 mongosh satisfaction --quiet --eval \\\n",
    "'print(\"******** Q2 ******** \");\n",
    "\n",
    "'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bbc022",
   "metadata": {},
   "source": [
    "*Q3*. Durchschnittliche Projektdauer pro Department "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d76f994",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo docker exec -i dbis-mongo-db-1 mongosh satisfaction --quiet --eval \\\n",
    "'print(\"******** Q3 ******** \");\n",
    "\n",
    "'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60848e0",
   "metadata": {},
   "source": [
    "*Q4*. Durchschnittliche Sat. pro Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f558bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo docker exec -i dbis-mongo-db-1 mongosh satisfaction --quiet --eval \\\n",
    "'print(\"******** Q4 ******** \");\n",
    "\n",
    "'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e6105",
   "metadata": {},
   "source": [
    "*Q5.* Durchschnittliche Projektdauer des \"Technology\" Departments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c1d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo docker exec -i dbis-mongo-db-1 mongosh satisfaction --quiet --eval \\\n",
    "'print(\"******** Q5 ******** \");\n",
    "\n",
    "'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cdb551",
   "metadata": {},
   "source": [
    "*Q6.* Satisfaction des \"Technology\" Departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo docker exec -i dbis-mongo-db-1 mongosh satisfaction --quiet --eval \\\n",
    "'print(\"******** Q6 ******** \");\n",
    "\n",
    "'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9399bda4",
   "metadata": {},
   "source": [
    "Der MongoDB-Container kann abschließend folgendermaßen wieder gestoppt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d7ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# stop the mongodb docker container\n",
    "if [ -z $(sudo docker ps --filter \"name=dbis-mongo-db-1\" -q) ]; then\n",
    "    printf \"\\nthe container does not exist\\n\";\n",
    "else \n",
    "    printf \"\\nstopping the container ...\\n\";\n",
    "    sudo docker stop dbis-mongo-db-1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c6092a",
   "metadata": {},
   "source": [
    "## Cassandra\n",
    "\n",
    "Abschließend, beschäftigen wir uns mit der Modellierung und Import bezüglich des spalten-orientierten Datenbanksystems Cassandra.\n",
    "\n",
    "Machen sie sich hierzu zunächst mit der Daten-Modellierung in Cassandra vertraut (siehe: [https://cassandra.apache.org/doc/latest/cassandra/data_modeling/index.html](https://cassandra.apache.org/doc/latest/cassandra/data_modeling/index.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c806e06",
   "metadata": {},
   "source": [
    "### Datenmodellierung    \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 9**    \n",
    "    \n",
    "Erstellen Sie ein *Chebotko logical data model* bezüglich der Datenbankabfragen *Q1, Q2, Q5, Q6* (siehe [https://cassandra.apache.org/doc/latest/cassandra/data_modeling/data_modeling_logical.html](https://cassandra.apache.org/doc/latest/cassandra/data_modeling/data_modeling_logical.html)). Beachten Sie dabei, dass wir jetzt - im Gegensatz zu der Modellierung und Import bei PostgreSQL und MongoDB - nur die in den Abfragen benötigten Attribute modellieren und importieren. Beachten Sie außerdem, dass wir im Gegensatzt zu dem in der Cassandra-Dokumentation verwendeten \"Hotel-Beispiel\" keinen Workflow zwischen den Abfragen haben und somit die \"Tabellen\" in unserem Diagramm auch nicht in Bezug zueinander stehen werden.\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "- **Q1.** Anzahl Projekte pro Department \n",
    "- **Q2.** Durchschnittliche Dauer aller Projekte \n",
    "- **Q5.** Durchschnittliche Projektdauer des \"Technology\" Departments \n",
    "- **Q6.** Durchschnittliche Employee satisfaction des \"Technology\" Departments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082d2690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%plantuml --jar\n",
    "\n",
    "@startuml\n",
    "\n",
    "hide members\n",
    "hide circle\n",
    "show fields\n",
    "\n",
    "class **A**<Q1> {\n",
    "a  **K**\n",
    "b  **C↑**\n",
    "c  **S**\n",
    "}\n",
    "\n",
    "class **B**<Q2> {\n",
    "a  **K**\n",
    "b  **C↑**\n",
    "c\n",
    "}\n",
    "\n",
    "@enduml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c2cd55",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 10**    \n",
    "    \n",
    "Erstellen Sie jetzt ein *Chebotko physical data model*. Fassen Sie dabei, wenn möglich, Tabellen aus der logischen Modellierung (eine Tabelle je Abfrage) zusammen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124253d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%plantuml --jar\n",
    "\n",
    "@startuml\n",
    "\n",
    "\n",
    "@enduml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d813958",
   "metadata": {},
   "source": [
    "### Datenimport\n",
    "\n",
    "Starten Sie eine Cassandra Datenbank. Das hier verwendete Docker-Image beinhaltete bereits den DataStax Bulk Reader für einen effizienten Import von CSV-Dateien ([https://docs.datastax.com/en/dsbulk/docs/dsbulkAbout.html](https://docs.datastax.com/en/dsbulk/docs/dsbulkAbout.html)).\n",
    "\n",
    "> *HINWEIS:* Denken Sie bezüglich der zu importierenden Dateien auch hier wieder daran den vollständigen Pfad des Volumes anzugeben (`-v /PATH/ON/HOST:/PATH/INSIDE/CONTAINER`), das im Datenbank-Container verfügbar sein soll. Also das Verzeichnis, das die zu importierenden CSV-Dateien enthält. Hier muss der absolute Pfad des entsprechenden Verzeichnisses auf ihrem Rechner (Host) angegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo docker run -d --rm \\\n",
    "--name dbis-cassandra-db-1 \\\n",
    "--hostname dbis-cassandra-db-1 \\\n",
    "-v \"/CHANGE/ME!!!:/mnt/workspace:ro\" \\\n",
    "--network dbis-hadoop-cluster-network \\\n",
    "-p 127.0.0.1:9042:9042 \\\n",
    "-p 127.0.0.1:9160:9160 \\\n",
    "registry.dbis-pro1.fernuni-hagen.de/pub-access/data-engineering-infrastructure/cassandra:4.0.4-dsbulk-1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472201e6",
   "metadata": {},
   "source": [
    "Vergewissern Sie sich, dass der Docker-Container läuft:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccca729",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo docker ps --filter \"name=dbis-cassandra-db-1\" --format \"table {{.Names}}\\t{{.Status}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb6bc6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 11**    \n",
    "    \n",
    "Vervollständigen Sie jetzt das nachfolgende CQL-Skript für die Erzeugung des Schemas.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939b82af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat <<\"EOF\" | sudo docker exec -i dbis-cassandra-db-1 cqlsh\n",
    "\n",
    "DROP KEYSPACE IF EXISTS satisfaction;\n",
    "CREATE KEYSPACE satisfaction\n",
    "    WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};\n",
    "\n",
    "USE satisfaction;\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "DESCRIBE KEYSPACE satisfaction;\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0363bd2f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 12**    \n",
    "    \n",
    "Erzeugen Sie zunächst die für den Import in Cassandra benötigten CSV-Dateien. Hier sind wieder unterschiedliche Vorgehensweisen denkbar. Beispielsweise haben wir die Daten bereits in PostgreSQL importiert und könnten diese durch den COPY-TO-Befehl in der benötigten Form exportierten. Es steht Ihnen an dieser Stelle ebenfalls wieder Frei auf welche Weise die Daten in die benötigte Struktur überführt und importiert werden. Der Python-Treiber für Cassandra ([*cassandra-driver*](https://docs.datastax.com/en/developer/python-driver/3.25/)) ist ebenfalls bereits installiert.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b4a44",
   "metadata": {},
   "source": [
    "Ihre Lösung ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e4d76b",
   "metadata": {},
   "source": [
    "Codeauschnitt für die Verwendung des Python-Treibers (Verbindungsaufbau mit einer Cassandra-Datenbank mithilfe des *cassandra-driver* Python-Modules):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from pprint import pprint\n",
    "\n",
    "cassandra_cluster = Cluster(['dbis-cassandra-db-1'])\n",
    "cassandra_session = cassandra_cluster.connect()\n",
    "cassandra_session.set_keyspace('satisfaction')\n",
    "\n",
    "cassandra_query = \"\"\"\n",
    "SELECT \n",
    "  ...\n",
    "FROM \n",
    "  ...\n",
    "\"\"\"\n",
    "\n",
    "result_rows = cassandra_session.execute(cassandra_query)\n",
    "pprint(list(result_rows))\n",
    "\n",
    "cassandra_cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73178a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 13**    \n",
    "    \n",
    "Importieren Sie die zuvor erzeugten CSV-Dateien mithilfe von DSBulk (falls kein abweichendes Vorgehen gewählt wurde).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ead82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo docker exec -i dbis-cassandra-db-1 dsbulk load \\\n",
    "--connector.name csv \\\n",
    "--connector.csv.url /path/to/file.csv \\\n",
    "--connector.csv.delimiter ',' \\\n",
    "--engine.dryRun false \\\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba355ef",
   "metadata": {},
   "source": [
    "### Datenbankabfragen    \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 14**    \n",
    "    \n",
    "Führen Sie die Abfragen jetzt auf Cassandra (CQL) aus.\n",
    "Alternativ zu dem vorgegebenen Rahmen (Verwendung der CQL-Shell) können Sie ebenfalls das *cassandra-driver* Python-Modul verwenden.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ac56c",
   "metadata": {},
   "source": [
    "Vorgegebener \"Rahmen\" für die Verwendung der CQL-Shell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4126700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# --------------\n",
    "## Q1\n",
    "# --------------\n",
    "printf \"# ------------\\n# Q1\\n# ------------\\n\"\n",
    "cat <<\"EOF\" | sudo docker exec -i dbis-cassandra-db-1 cqlsh -k satisfaction\n",
    "\n",
    "SELECT \n",
    "  ...\n",
    "FROM \n",
    "  ...\n",
    "\n",
    "EOF\n",
    "\n",
    "# --------------\n",
    "## Q2\n",
    "# --------------\n",
    "printf \"# ------------\\n# Q2\\n# ------------\\n\"\n",
    "cat <<\"EOF\" | sudo docker exec -i dbis-cassandra-db-1 cqlsh -k satisfaction\n",
    "\n",
    "SELECT \n",
    "  ...\n",
    "FROM \n",
    "  ...\n",
    "\n",
    "EOF\n",
    "\n",
    "\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ede01",
   "metadata": {},
   "source": [
    "Der Cassandra-Container kann abschließend folgendermaßen gestoppt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd79e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# stop the cassandra docker container\n",
    "if [ -z $(sudo docker ps --filter \"name=dbis-cassandra-db-1\" -q) ]; then\n",
    "    printf \"\\nthe container does not exist\\n\";\n",
    "else \n",
    "    printf \"\\nstopping the container ...\\n\";\n",
    "    sudo docker stop dbis-cassandra-db-1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d57b97",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 15**    \n",
    "    \n",
    "Beschreiben Sie, warum Abfragen wie *Q1* und *Q2* bei Cassandra zu Problemen führen könnten.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b85d62",
   "metadata": {},
   "source": [
    "Ihre Lösung ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e37536",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Aufgabe 16**    \n",
    "    \n",
    "Die empfohlene Größe für Partitionen in Cassandra beträgt 100.000 Cells. Berechnen Sie die Größe der aktuell größten Partition (siehe [https://cassandra.apache.org/doc/latest/cassandra/data_modeling/data_modeling_refining.html](https://cassandra.apache.org/doc/latest/cassandra/data_modeling/data_modeling_refining.html)). Welche Möglichkeiten bzw. Modellierungsstrategien bezüglich des Schema-Designs gibt es, um zu große Partitionen zu vermeiden?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4f5dfa",
   "metadata": {},
   "source": [
    "Berechnung der *partition size*:\n",
    "\n",
    "$$ N_v = N_r(N_c - N_{pk} − N_s) + N_s $$\n",
    "\n",
    "$$ N_v = \\text{Number of values (or cells)} $$\n",
    "$$ N_s = \\text{Number of static columns} $$\n",
    "$$ N_r = \\text{Number of rows} $$\n",
    "$$ N_c = \\text{Number of columns} $$\n",
    "$$ N_{pk} = \\text{Number of primary key columns} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7357c15",
   "metadata": {},
   "source": [
    "Ihre Lösung ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0963d54f",
   "metadata": {},
   "source": [
    "---\n",
    "Der PDF-Export dieses Jupyter-Notebooks kann alternativ durch folgenden Aufruf erfolgen (Pfad zum Notebook muss entsprechend angepasst werden!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e69633",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to pdf --template '/home/pyspark-client/nbconvert-templates/fernuni-latex' \\\n",
    "~/workspace/PATH/TO/KE6-7.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1168c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
